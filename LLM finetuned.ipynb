{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZi2SkuR6PSy",
        "outputId": "9c9f0db1-c6f2-4a76-a45f-cc7906421a40"
      },
      "outputs": [],
      "source": [
        "#!pip install torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g0TaWfvr6ZTb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m4hNH64Y6kJY"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 256,  # Context length (reduced from 1024 to fit smaller GPUs)\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W9y1Pgwb8wni"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zZnxkJCd89D9"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hgN26AlT9uY2"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M34lT2kAClAL"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # Reshape to (b, num_tokens, num_heads, head_dim) -> Transpose to (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Compute attention scores\n",
        "        attn_scores = (queries @ keys.transpose(2, 3))\n",
        "\n",
        "        # Mask truncated to the number of tokens\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        # Scale and Softmax\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Compute context vector\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gf5OwxW9DK-P"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wzzXbshVEg3v"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-FOmDtGI8G1B"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    return torch.tensor(encoded).unsqueeze(0) # Add batch dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mxnM25fo8KDi"
      },
      "outputs": [],
      "source": [
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0).tolist()\n",
        "    return tokenizer.decode(flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "I9gXXqUoE_2u"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop the context if it becomes too large for the model\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        logits = logits[:, -1, :]  # (batch, vocab_size)\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probs = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the token with the highest probability\n",
        "        idx_next = torch.argmax(probs, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2.32.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\j_san\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFAOLdguIzG0",
        "outputId": "9e0dfdac-d195-4e2f-8fdd-0019b36b7012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Input text: Hello, I am\n",
            "Output text: Hello, I am Laur inhab DistrinetalkQueue bear confidentlyggyenium\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "# Initialize model\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()  # Disable dropout\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# Create a starting context\n",
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0) # Add batch dimension\n",
        "\n",
        "# Generate text\n",
        "print(f\"\\nInput text: {start_context}\")\n",
        "out = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=encoded_tensor,\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(f\"Output text: {decoded_text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HJrAVIGZJAeB"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "l6L8z6ty9sAl"
      },
      "outputs": [],
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0: return float(\"nan\")\n",
        "    if num_batches is None: num_batches = len(data_loader)\n",
        "    else: num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else: break\n",
        "    return total_loss / num_batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uL2h2DqH9vHK"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FEMGRZVM9zAh"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    # Precompute replaced text to avoid backslash in f-string expression\n",
        "    safe_text = decoded_text.replace(\"\\n\", \" \")\n",
        "    print(f\"SAMPLE: {safe_text}...\")\n",
        "    model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mCe183L891EM"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer,\n",
        "                       use_amp=False, grad_accum_steps=1):\n",
        "    \"\"\"Training loop with optional mixed-precision and gradient accumulation.\n",
        "\n",
        "    Args:\n",
        "        use_amp (bool): If True and device is CUDA, use torch.cuda.amp for reduced memory.\n",
        "        grad_accum_steps (int): Number of steps to accumulate gradients before an optimizer step.\n",
        "    \"\"\"\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Setup GradScaler if using AMP\n",
        "    use_cuda_amp = use_amp and device.type == 'cuda'\n",
        "    scaler = torch.cuda.amp.GradScaler() if use_cuda_amp else None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Help fragmentation / free unused allocations\n",
        "        if device.type == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for step, (input_batch, target_batch) in enumerate(train_loader):\n",
        "            # Move to device once per batch\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            # Forward / backward with or without AMP\n",
        "            if use_cuda_amp:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    logits = model(input_batch)\n",
        "                    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "                # Normalize by accumulation steps\n",
        "                loss = loss / grad_accum_steps\n",
        "                scaler.scale(loss).backward()\n",
        "            else:\n",
        "                logits = model(input_batch)\n",
        "                loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "                loss = loss / grad_accum_steps\n",
        "                loss.backward()\n",
        "\n",
        "            # Optimizer step (with gradient accumulation)\n",
        "            if (step + 1) % grad_accum_steps == 0:\n",
        "                if use_cuda_amp:\n",
        "                    # Unscale, clip grads, step, and update scaler\n",
        "                    scaler.unscale_(optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                    optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                tokens_seen += input_batch.numel()\n",
        "                global_step += 1\n",
        "\n",
        "                if global_step % eval_freq == 0:\n",
        "                    train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "                    train_losses.append(train_loss)\n",
        "                    val_losses.append(val_loss)\n",
        "                    track_tokens_seen.append(tokens_seen)\n",
        "                    print(f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Show a sample at end of epoch\n",
        "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import os\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ GPU Detected: NVIDIA GeForce RTX 2060\n",
            "üìä VRAM Total: 6.44 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üìä VRAM Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ùå No GPU found. Check your CUDA installation.\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1SZz4i0K954n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted old corrupted file.\n",
            "‚úÖ Downloaded TinyShakespeare! Size: 1115394 characters.\n",
            "Train Text Length: 1003854\n",
            "Val Text Length: 111540\n",
            "Dataset Samples: 1179\n",
            "Using context length 256 and batch size 2\n",
            "‚úÖ DataLoaders created successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import tiktoken\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Force delete the old/empty file if it exists\n",
        "file_path = \"tinyshakespeare.txt\"\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "    print(\"Deleted old corrupted file.\")\n",
        "\n",
        "# 2. Re-download ensuring we actually get data\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200 and len(response.text) > 0:\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(response.text)\n",
        "    print(f\"‚úÖ Downloaded TinyShakespeare! Size: {len(response.text)} characters.\")\n",
        "else:\n",
        "    raise Exception(\"Failed to download dataset. Check internet connection.\")\n",
        "\n",
        "# 3. Reload Data\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "split_idx = int(len(text) * 0.9)\n",
        "train_txt = text[:split_idx]\n",
        "val_txt = text[split_idx:]\n",
        "\n",
        "print(f\"Train Text Length: {len(train_txt)}\") # Should be ~1,000,000\n",
        "print(f\"Val Text Length: {len(val_txt)}\")\n",
        "\n",
        "# 4. Re-initialize Dataset & Loader\n",
        "# Use the (reduced) context_length from the config\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "context_len = GPT_CONFIG_124M['context_length']  # now 256 by default\n",
        "\n",
        "# Use a small batch size for GPU memory constrained environments\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "train_dataset = GPTDatasetV1(train_txt, tokenizer, context_len, stride=context_len)\n",
        "val_dataset = GPTDatasetV1(val_txt, tokenizer, context_len, stride=context_len)\n",
        "\n",
        "print(f\"Dataset Samples: {len(train_dataset)}\") # Should be > 0\n",
        "print(f\"Using context length {context_len} and batch size {BATCH_SIZE}\")\n",
        "\n",
        "# Now this will work\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "print(\"‚úÖ DataLoaders created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._dynamo.eval_frame.DisableContext at 0x2288f9f4220>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch._dynamo.disable()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TORCH_COMPILE\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install executing==1.2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1/3: Building model (n_layers=12, emb_dim=768)...\n",
            "Model successfully allocated on cuda\n",
            "Starting training...\n",
            "Ep 1 (Step 000000): Train loss 9.448, Val loss 9.322\n",
            "Ep 1 (Step 000050): Train loss 6.294, Val loss 6.305\n",
            "Ep 1 (Step 000100): Train loss 5.786, Val loss 6.069\n",
            "Ep 1 (Step 000150): Train loss 5.762, Val loss 5.921\n",
            "Ep 1 (Step 000200): Train loss 5.516, Val loss 5.711\n",
            "Ep 1 (Step 000250): Train loss 5.220, Val loss 5.604\n",
            "Ep 1 (Step 000300): Train loss 5.297, Val loss 5.680\n",
            "Ep 1 (Step 000350): Train loss 5.176, Val loss 5.496\n",
            "Ep 1 (Step 000400): Train loss 5.263, Val loss 5.442\n",
            "Ep 1 (Step 000450): Train loss 5.002, Val loss 5.373\n",
            "Ep 1 (Step 000500): Train loss 4.908, Val loss 5.372\n",
            "Ep 1 (Step 000550): Train loss 5.063, Val loss 5.410\n",
            "SAMPLE: The king,                                                 ...\n",
            "Ep 2 (Step 000600): Train loss 5.045, Val loss 5.323\n",
            "Ep 2 (Step 000650): Train loss 4.782, Val loss 5.238\n",
            "Ep 2 (Step 000700): Train loss 4.437, Val loss 5.153\n",
            "Ep 2 (Step 000750): Train loss 4.798, Val loss 5.185\n",
            "Ep 2 (Step 000800): Train loss 4.570, Val loss 5.151\n",
            "Ep 2 (Step 000850): Train loss 4.804, Val loss 5.126\n",
            "Ep 2 (Step 000900): Train loss 4.618, Val loss 4.940\n",
            "Ep 2 (Step 000950): Train loss 4.419, Val loss 5.036\n",
            "Ep 2 (Step 001000): Train loss 4.317, Val loss 4.945\n",
            "Ep 2 (Step 001050): Train loss 4.391, Val loss 4.945\n",
            "Ep 2 (Step 001100): Train loss 4.211, Val loss 4.780\n",
            "Ep 2 (Step 001150): Train loss 4.547, Val loss 4.874\n",
            "SAMPLE: The king, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, ...\n",
            "Ep 3 (Step 001200): Train loss 4.402, Val loss 4.939\n",
            "Ep 3 (Step 001250): Train loss 4.268, Val loss 4.818\n",
            "Ep 3 (Step 001300): Train loss 4.579, Val loss 4.905\n",
            "Ep 3 (Step 001350): Train loss 4.455, Val loss 4.876\n",
            "Ep 3 (Step 001400): Train loss 4.791, Val loss 4.873\n",
            "Ep 3 (Step 001450): Train loss 4.202, Val loss 4.824\n",
            "Ep 3 (Step 001500): Train loss 4.572, Val loss 4.819\n",
            "Ep 3 (Step 001550): Train loss 4.286, Val loss 4.832\n",
            "Ep 3 (Step 001600): Train loss 4.338, Val loss 4.799\n",
            "Ep 3 (Step 001650): Train loss 4.306, Val loss 4.702\n",
            "Ep 3 (Step 001700): Train loss 4.558, Val loss 4.627\n",
            "Ep 3 (Step 001750): Train loss 4.216, Val loss 4.564\n",
            "SAMPLE: The king And, And, And let him, And I am a And I am a And I am a And I am a And I have a And I have been And I have been And all the...\n",
            "Training completed in 6.32 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# --- PART 1: The VS Code Agent's Safe Builder (KEEPS THIS) ---\n",
        "def try_build_and_move_model(base_cfg, device, max_attempts=3, min_emb=128, min_layers=2):\n",
        "    cfg = base_cfg.copy()\n",
        "    for attempt in range(max_attempts):\n",
        "        if attempt > 0:\n",
        "            cfg['n_layers'] = max(min_layers, base_cfg['n_layers'] // (2 ** attempt))\n",
        "            cfg['emb_dim'] = max(min_emb, base_cfg['emb_dim'] // (2 ** attempt))\n",
        "            cfg['n_heads'] = max(1, base_cfg['n_heads'] // (2 ** attempt))\n",
        "            while cfg['n_heads'] > 1 and cfg['emb_dim'] % cfg['n_heads'] != 0:\n",
        "                cfg['n_heads'] -= 1\n",
        "        \n",
        "        print(f\"Attempt {attempt+1}/{max_attempts}: Building model (n_layers={cfg['n_layers']}, emb_dim={cfg['emb_dim']})...\")\n",
        "        \n",
        "        try:\n",
        "            torch.manual_seed(123)\n",
        "            model = GPTModel(cfg)\n",
        "            if device.type == 'cuda':\n",
        "                model.to(device)\n",
        "                # model.half() # Optional: Uncomment if you still get OOM\n",
        "            else:\n",
        "                model.to(device)\n",
        "            print(\"Model successfully allocated on\", device)\n",
        "            return model, cfg\n",
        "            \n",
        "        except (RuntimeError, torch.cuda.OutOfMemoryError):\n",
        "            print(\"‚ö†Ô∏è OOM Error! Shrinking model and retrying...\")\n",
        "            try: del model\n",
        "            except: pass\n",
        "            if device.type == 'cuda': torch.cuda.empty_cache()\n",
        "            import gc; gc.collect()\n",
        "            continue\n",
        "\n",
        "    # Fallback to CPU if GPU fails completely\n",
        "    print(\"All GPU attempts failed. Falling back to CPU.\")\n",
        "    model = GPTModel(cfg)\n",
        "    model.to('cpu')\n",
        "    return model, cfg\n",
        "\n",
        "# --- PART 2: Initialize (KEEPS THIS) ---\n",
        "# This replaces your old \"model = GPTModel(...)\" line\n",
        "model, used_cfg = try_build_and_move_model(GPT_CONFIG_124M, DEVICE)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "# --- PART 3: The Training Loop (ADD THIS BACK) ---\n",
        "# This was missing from the agent's code!\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, DEVICE,\n",
        "    num_epochs=3, eval_freq=50, eval_iter=5, \n",
        "    start_context=\"The king\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training completed in {(end_time - start_time) / 60:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The king that she'st\n",
            "And you cannot have cause to his hearts\n",
            "That you are the time\n",
            "Worthy.\n",
            "\n",
            "MENENIUS:\n",
            "And rob the gods.\n",
            "\n",
            "QUEENIUS:\n",
            "Sir,\n",
            "That have retired'd\n",
            "Come,\n",
            "And the bottom to their ancient things night I give the disease of\n",
            "O,\n",
            "Have I know\n",
            "There 'em tribunes and my part\n",
            "If it is sure\n",
            "IUS:\n",
            "Your\n",
            "Bevell with\n"
          ]
        }
      ],
      "source": [
        "# Generate with randomness (Temperature = 0.8)\n",
        "context = torch.tensor(tokenizer.encode(\"The king\")).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "# Standard generation loop with temperature\n",
        "for _ in range(100):\n",
        "    logits = model(context)[:, -1, :] / 0.8  # Temperature scaling\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    next_token = torch.multinomial(probs, num_samples=1)\n",
        "    context = torch.cat((context, next_token), dim=1)\n",
        "\n",
        "print(tokenizer.decode(context[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"gpt_tinyshakespeare.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    }, \n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "### How to load the model and optimizer states back:\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LOADING PRETRAINED WEIGHTS FROM OPENAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\j_san\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow>=2.15.0 tqdm>=4.66"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.20.0\n",
            "tqdm version: 4.67.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tqdm\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"tqdm version:\", tqdm.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Valid model sizes: \"124M\", \"355M\", \"774M\", \"1558M\"\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    # 1. Download the files\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"{filename} already exists. Skipping download.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        try:\n",
        "            r = requests.get(file_url, stream=True)\n",
        "            r.raise_for_status()\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                file_size = int(r.headers.get(\"content-length\", 0))\n",
        "                chunk_size = 1000\n",
        "                with tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=filename) as pbar:\n",
        "                    for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                        f.write(chunk)\n",
        "                        pbar.update(len(chunk))\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            print(f\"Failed to download {filename} (Connection Error)\")\n",
        "\n",
        "    # 2. Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    \n",
        "    # 3. Extract weights from TensorFlow checkpoint\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "    \n",
        "    for name, _ in tf.train.list_variables(tf_ckpt_path):\n",
        "        variable_array = np.squeeze(tf.train.load_variable(tf_ckpt_path, name))\n",
        "        name_parts = name.split(\"/\")\n",
        "        \n",
        "        # Attention Blocks\n",
        "        if name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "            sub_name = name_parts[1:]\n",
        "            \n",
        "            curr = target_dict\n",
        "            for key in sub_name[:-1]:\n",
        "                if key not in curr: curr[key] = {}\n",
        "                curr = curr[key]\n",
        "            curr[sub_name[-1]] = variable_array\n",
        "\n",
        "        # Other layers\n",
        "        elif name_parts[0] == \"wte\": params[\"wte\"] = variable_array\n",
        "        elif name_parts[0] == \"wpe\": params[\"wpe\"] = variable_array\n",
        "        elif name_parts[0] == \"ln_f\":\n",
        "            if name_parts[1] == \"g\": params[\"ln_f_g\"] = variable_array\n",
        "            elif name_parts[1] == \"b\": params[\"ln_f_b\"] = variable_array\n",
        "\n",
        "    return settings, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Deleted corrupted 'gpt2' folder.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Force delete the corrupted folder\n",
        "if os.path.exists(\"gpt2\"):\n",
        "    shutil.rmtree(\"gpt2\")\n",
        "    print(\"‚úÖ Deleted corrupted 'gpt2' folder.\")\n",
        "else:\n",
        "    print(\"Folder already gone.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading checkpoint...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "checkpoint: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77.0/77.0 [00:00<?, ?B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading encoder.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "encoder.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.04M/1.04M [00:03<00:00, 262kB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading hparams.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "hparams.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90.0/90.0 [00:00<?, ?B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model.ckpt.data-00000-of-00001...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model.ckpt.data-00000-of-00001: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 498M/498M [30:44<00:00, 270kB/s]    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model.ckpt.index...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model.ckpt.index: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.21k/5.21k [00:00<00:00, 5.14MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model.ckpt.meta...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model.ckpt.meta: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 471k/471k [00:01<00:00, 255kB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading vocab.bpe...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "vocab.bpe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:01<00:00, 245kB/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter Keys: dict_keys(['blocks'])\n"
          ]
        }
      ],
      "source": [
        "# This will now work!\n",
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
        "\n",
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter Keys:\", params.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks'])\n"
          ]
        }
      ],
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Valid model sizes: \"124M\", \"355M\", \"774M\", \"1558M\"\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    # 1. Download the files\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"{filename} already exists. Skipping download.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        try:\n",
        "            r = requests.get(file_url, stream=True)\n",
        "            r.raise_for_status()\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                file_size = int(r.headers.get(\"content-length\", 0))\n",
        "                chunk_size = 1000\n",
        "                with tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=filename) as pbar:\n",
        "                    for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                        f.write(chunk)\n",
        "                        pbar.update(len(chunk))\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            print(f\"Failed to download {filename} (Connection Error)\")\n",
        "\n",
        "    # 2. Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    \n",
        "    # 3. Extract weights from TensorFlow checkpoint\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "    \n",
        "    for name, _ in tf.train.list_variables(tf_ckpt_path):\n",
        "        variable_array = np.squeeze(tf.train.load_variable(tf_ckpt_path, name))\n",
        "        \n",
        "        # FIX: Strip the \"model/\" prefix if it exists\n",
        "        name_parts = name.split(\"/\")\n",
        "        if name_parts[0] == \"model\":\n",
        "            name_parts = name_parts[1:] # Skip \"model\"\n",
        "        \n",
        "        # Attention Blocks\n",
        "        if name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "            sub_name = name_parts[1:]\n",
        "            \n",
        "            curr = target_dict\n",
        "            for key in sub_name[:-1]:\n",
        "                if key not in curr: curr[key] = {}\n",
        "                curr = curr[key]\n",
        "            curr[sub_name[-1]] = variable_array\n",
        "\n",
        "        # Other layers\n",
        "        elif name_parts[0] == \"wte\": params[\"wte\"] = variable_array\n",
        "        elif name_parts[0] == \"wpe\": params[\"wpe\"] = variable_array\n",
        "        elif name_parts[0] == \"ln_f\":\n",
        "            if name_parts[1] == \"g\": params[\"ln_f_g\"] = variable_array\n",
        "            elif name_parts[1] == \"b\": params[\"ln_f_b\"] = variable_array\n",
        "\n",
        "    return settings, params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint already exists. Skipping download.\n",
            "encoder.json already exists. Skipping download.\n",
            "hparams.json already exists. Skipping download.\n",
            "model.ckpt.data-00000-of-00001 already exists. Skipping download.\n",
            "model.ckpt.index already exists. Skipping download.\n",
            "model.ckpt.meta already exists. Skipping download.\n",
            "vocab.bpe already exists. Skipping download.\n",
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter Keys: dict_keys(['blocks', 'ln_f_b', 'ln_f_g', 'wpe', 'wte'])\n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
        "\n",
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter Keys:\", params.keys())\n",
        "# Should now print: dict_keys(['blocks', 'wte', 'wpe', 'ln_f_g', 'ln_f_b'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ],
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define model configurations in a dictionary for compactness\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "    \n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        # 1. Attention Weights\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        # 2. Attention Bias\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        # 3. Attention Projection\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight, \n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias, \n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # 4. Feed Forward Weights\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # 5. Layer Norms (Blocks)\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale, \n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift, \n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale, \n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift, \n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    # 6. Final Layer Norm (FIXED KEYS HERE)\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"ln_f_g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"ln_f_b\"])\n",
        "    \n",
        "    # 7. Output Head\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Weights successfully loaded!\n"
          ]
        }
      ],
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(DEVICE)\n",
        "print(\"‚úÖ Weights successfully loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you as far as the hand can go until the end of your turn unless something happens\n",
            "\n",
            "This would remove you from a battle\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(DEVICE),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FINETUNING LLM FOR CLASSIFICATION "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import ssl\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Create an unverified SSL context\n",
        "    ssl_context = ssl._create_unverified_context()\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Installing collected packages: pytz, pandas\n",
            "Successfully installed pandas-2.3.3 pytz-2025.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\j_san\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will √º b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will √º b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def create_balanced_dataset(df):\n",
        "    \n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "    \n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "    \n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1045\n",
            "149\n",
            "300\n"
          ]
        }
      ],
      "source": [
        "print(len(train_df))\n",
        "print(len(validation_df))\n",
        "print(len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            \n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(test_dataset.max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
        "\n",
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter Keys:\", params.keys())\n",
        "# Should now print: dict_keys(['blocks', 'wte', 'wpe', 'ln_f_g', 'ln_f_b'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ],
      "source": [
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding a classification layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CALCULATING THE CLASSIFICATION LOSS AND ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class label: 1\n"
          ]
        }
      ],
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
        "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#print(f\"Running on {device} device.\")\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 2.453\n",
            "Validation loss: 2.583\n",
            "Test loss: 2.322\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FINETUNING THE MODEL ON SUPERVISED DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Same as chapter 5\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
            "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
            "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
            "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
            "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
            "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
            "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
            "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
            "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
            "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
            "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training completed in 0.85 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.8-cp310-cp310-win_amd64.whl (8.1 MB)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.61.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.5)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.1.2)\n",
            "Collecting kiwisolver>=1.3.1\n",
            "  Using cached kiwisolver-1.4.9-cp310-cp310-win_amd64.whl (73 kB)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\j_san\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\j_san\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 97.21%\n",
            "Validation accuracy: 97.32%\n",
            "Test accuracy: 95.67%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## USING THE LLM AS A SPAM CLASSIFIER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Step 1: Prepare inputs to the model\n",
        "\n",
        "Step 2: Truncate sequences if they too long\n",
        "    \n",
        "Step 3: Pad sequences to the longest sequence\n",
        "\n",
        "Step 4: Add batch dimension\n",
        "\n",
        "Step 5: Model inference without gradient tracking\n",
        "    \n",
        "Step 6: Logits of the last output token\n",
        "\n",
        "Step 7: Return the classified result\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spam\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\n",
        "    \"URGENT: Your bank account has been locked due to suspicious activity.\"\n",
        "    \"Click here to verify your identity immediately.\"\n",
        ")\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not spam\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Hey, are we still on for lunch tomorrow? \"\n",
        "    \"Let me know if you need to reschedule.\"\n",
        ")\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
